{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93732a1f",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6b34c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from six import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "from decisiontree import DecisionTree__Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a13c121",
   "metadata": {},
   "source": [
    "### Load the Iris Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af08a42",
   "metadata": {},
   "source": [
    "The famous **Iris** dataset consists of 150 samples of iris flowers divided into three species: **Setosa**, **Versicolor**, and **Virginica**.  \n",
    "\n",
    "The dataset contains four features (attributes) for each sample:\n",
    "- **Sepal length**, **Sepal width**, **Petal length**, and **Petal width**\n",
    "\n",
    "The **target** variable (class label) is the species of the iris flower: Label **0** for **Setosa**, **1** for **Versicolor**, and **2** for **Virginica**.\n",
    "\n",
    "Here is the picture of three Iris Flower spieces.\n",
    "<img src=\"Iris.png\" alt=\"Iris Dataset Screenshot\" width=\"600\" height=\"400\"/>\n",
    "\n",
    "Here is a dataset sample.\n",
    "<img src=\"iris2.png\" alt=\"Iris Dataset Screenshot\" width=\"600\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d17444",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a11c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91acb155",
   "metadata": {},
   "source": [
    "### Function to create Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6c0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_visualize_and_test(criterion, max_depth = None, min_samples_split = 2, min_samples_leaf = 1):\n",
    "    \n",
    "    # Training the model\n",
    "    clf = DecisionTree__Classifier(criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "\n",
    "    # Evaluating accuracy\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    print(f\"Training accuracy: {accuracy_train}\")\n",
    "    print(f\"Test accuracy: {accuracy_test}\")\n",
    "    dot_data = clf.export__graphviz(feature_names=iris.feature_names, class_names=iris.target_names)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43da5799",
   "metadata": {},
   "source": [
    "### Overfit Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8e8f1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9466666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Temp\\\\iris_entropy_overfit.pdf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and visualize with entropy\n",
    "graph_entropy_en_overfit = train_and_visualize_and_test(criterion = 'entropy')\n",
    "graph_entropy_en_overfit.render(\"Temp/iris_entropy_overfit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "581ed29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Temp\\\\iris_gini_overfit.pdf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and visualize with Gini\n",
    "graph_entropy_g_overfit = train_and_visualize_and_test(criterion = 'gini')\n",
    "graph_entropy_g_overfit.render(\"Temp/iris_gini_overfit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920de81d",
   "metadata": {},
   "source": [
    "### Underfit Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff52005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.68\n",
      "Test accuracy: 0.6533333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Temp\\\\iris_entropy_underfit.pdf'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and visualize with Entropy\n",
    "graph_entropy_en_underfit = train_and_visualize_and_test(criterion = 'entropy', max_depth = 1)\n",
    "graph_entropy_en_underfit.render(\"Temp/iris_entropy_underfit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f65eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.68\n",
      "Test accuracy: 0.6533333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Temp\\\\iris_gini_underfit.pdf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and visualize with Gini\n",
    "graph_entropy_g_underfit = train_and_visualize_and_test(criterion = 'gini', max_depth = 1)\n",
    "graph_entropy_g_underfit.render(\"Temp/iris_gini_underfit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a2ab3",
   "metadata": {},
   "source": [
    "### Reduce Overfitting to improve the accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca191f1",
   "metadata": {},
   "source": [
    "**Pruning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f5f84a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9733333333333334\n",
      "Test accuracy: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Temp\\\\iris_gini_pruning_maxdepth.pdf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pruning with Max-Dept\n",
    "graph_entropy_g_pruning_maxdepth = train_and_visualize_and_test(criterion = 'gini', max_depth = 4)\n",
    "graph_entropy_g_pruning_maxdepth.render(\"Temp/iris_gini_pruning_maxdepth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d42ba59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9466666666666667\n",
      "Test accuracy: 0.9733333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Temp\\\\iris_gini_pruning_min_samples_leaf.pdf'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pruning by putting a restriction on the minimum no. of samples required to be at a leaf node\n",
    "graph_entropy_g_pruning_min_samples_leaf = train_and_visualize_and_test(criterion = 'gini', min_samples_leaf = 4)\n",
    "graph_entropy_g_pruning_min_samples_leaf.render(\"Temp/iris_gini_pruning_min_samples_leaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcb5aa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9733333333333334\n",
      "Test accuracy: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Temp\\\\iris_gini_pruning_min_samples_split.pdf'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pruning by putting a restriction on the minimum no. of samples required to split an internal node\n",
    "graph_entropy_g_pruning_min_samples_split = train_and_visualize_and_test(criterion = 'gini', min_samples_split = 4)\n",
    "graph_entropy_g_pruning_min_samples_split.render(\"Temp/iris_gini_pruning_min_samples_split\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
